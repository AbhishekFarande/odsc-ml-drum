{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_nxQLKVeYTy"
   },
   "source": [
    "# Drum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drum 1.3.0\r\n"
     ]
    }
   ],
   "source": [
    "!drum --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4p0zDG-VWJP"
   },
   "source": [
    "# Test scoring with Sklearn model using DRUM\n",
    "<a id=\"setup_complete\"></a>\n",
    "\n",
    "Next snippet is to test scoring.  The functionality can also be used to do batch scoring with the model.  \n",
    "\n",
    "`../src/custom_model` contains the sklearn pkl as well as the `custom.py` file which contains hooks that allow DRUM to hook into our pkl.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "C_OOeqEx6hqH",
    "outputId": "89c75e87-d13f-4f3d-c5e9-dec4c7e696e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected score mode\n",
      "Detected /Users/timothy.whittaker/Desktop/ODSC/odsc-ml-drum/src/custom_model/custom.py .. trying to load hooks\n",
      "\u001b[32m \u001b[0m\n",
      "\u001b[32m \u001b[0m\n",
      "\u001b[32m============================================================\u001b[0m\n",
      "\u001b[32mComponent: generic_predictor\u001b[0m\n",
      "\u001b[32mLanguage:  Python\u001b[0m\n",
      "\u001b[32mOutput:\u001b[0m\n",
      "\u001b[32m------------------------------------------------------------\u001b[0m\n",
      "\u001b[32m------------------------------------------------------------\u001b[0m\n",
      "\u001b[32mRuntime:    0.0 sec\u001b[0m\n",
      "\u001b[32mNR outputs: 0\u001b[0m\n",
      "\u001b[32m============================================================\u001b[0m\n",
      "\u001b[32m \u001b[0m\n",
      "    Predictions\n",
      "0        26.210\n",
      "1        22.140\n",
      "2        34.930\n",
      "3        34.735\n",
      "4        35.200\n",
      "5        26.795\n",
      "6        20.985\n",
      "7        25.035\n",
      "8        18.205\n",
      "9        18.805\n",
      "10       16.365\n",
      "11       19.440\n",
      "12       21.695\n",
      "13       20.010\n",
      "14       18.400\n",
      "15       19.685\n",
      "16       22.185\n",
      "17       18.350\n",
      "18       19.790\n",
      "19       18.740\n"
     ]
    }
   ],
   "source": [
    "!drum score --code-dir ../src/custom_model --input ../data/boston_housing_test.csv --target-type regression --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JmS971iweH6t"
   },
   "source": [
    "# Start the inference server locally\n",
    "\n",
    "When starting the server, we'll use `subprocess.Popen` so we may interact with the server in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "D7BrHC1gYjHD"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "import yaml\n",
    "import time\n",
    "import os\n",
    "import datarobot as dr\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_inference_server = [\"drum\",\n",
    "              \"server\",\n",
    "              \"--code-dir\",\"../src/custom_model\", \n",
    "              \"--address\", \"0.0.0.0:6789\", \n",
    "              \"--show-perf\",\n",
    "              \"--target-type\", \"regression\",\n",
    "              \"--logging-level\", \"info\",\n",
    "              \"--show-stacktrace\",\n",
    "              \"--verbose\"\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "jWvksr_sYlEr"
   },
   "outputs": [],
   "source": [
    "inference_server = subprocess.Popen(run_inference_server, stdout=subprocess.PIPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "peFenY-leJo3"
   },
   "source": [
    "## Ping the Server to make sure it is running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "jmh7SRfQVnTU",
    "outputId": "0bc5161d-84dd-4c05-d0fe-0962f1c74c52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check status\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'{\"message\":\"OK\"}\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## confirm the server is running\n",
    "time.sleep(5) ## snoozing before pinging the server to give it time to actually start\n",
    "print('check status')\n",
    "requests.request(\"GET\", \"http://0.0.0.0:6789/\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Pb6ev0dkbGeX"
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/content/datarobot-user-models/tests/testdata/boston_housing_inference.csv')\n",
    "df = pd.read_csv('../data/boston_housing_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "iZ-sZcHMYmRx"
   },
   "outputs": [],
   "source": [
    "def score(data):\n",
    "    b_buf = BytesIO()\n",
    "    b_buf.write(data.to_csv(index=False).encode(\"utf-8\"))\n",
    "    b_buf.seek(0)\n",
    "  \n",
    "    url = \"http://localhost:6789/predict/\"\n",
    "    files = [\n",
    "        ('X', b_buf)\n",
    "    ]\n",
    "    response = requests.request(\"POST\", url, files = files, timeout=None, verify=False)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JOsaTgXOeNMG"
   },
   "source": [
    "## Send data to server for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "yBV2UffU748S",
    "outputId": "a7b4a9d7-a8ac-4dec-93c4-a79977fda402"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "        b  lstat  \n",
       "0  396.90   4.98  \n",
       "1  396.90   9.14  \n",
       "2  392.83   4.03  \n",
       "3  394.63   2.94  \n",
       "4  396.90   5.33  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "HjdKXUcUWUXq",
    "outputId": "5091625d-208d-4335-cfff-35d6449a6f2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [26.21,\n",
      "                 22.14,\n",
      "                 34.93,\n",
      "                 34.735,\n",
      "                 35.2,\n",
      "                 26.795,\n",
      "                 20.985,\n",
      "                 25.035,\n",
      "                 18.205,\n",
      "                 18.805,\n",
      "                 16.365,\n",
      "                 19.44,\n",
      "                 21.695,\n",
      "                 20.01,\n",
      "                 18.4,\n",
      "                 19.685,\n",
      "                 22.185,\n",
      "                 18.35,\n",
      "                 19.79,\n",
      "                 18.74]}\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "predictions = score(df).json() ## score entire dataset but only show first 5 records\n",
    "pprint(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26.795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20.985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18.205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16.365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>21.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>18.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>19.685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>22.185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18.740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    predictions\n",
       "0        26.210\n",
       "1        22.140\n",
       "2        34.930\n",
       "3        34.735\n",
       "4        35.200\n",
       "5        26.795\n",
       "6        20.985\n",
       "7        25.035\n",
       "8        18.205\n",
       "9        18.805\n",
       "10       16.365\n",
       "11       19.440\n",
       "12       21.695\n",
       "13       20.010\n",
       "14       18.400\n",
       "15       19.685\n",
       "16       22.185\n",
       "17       18.350\n",
       "18       19.790\n",
       "19       18.740"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the Flask App\n",
    "\n",
    "Set a few environment variables for the flask app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"LC_ALL\"] = \"C.UTF-8\"\n",
    "os.environ[\"LANG\"] = \"C.UTF-8\"\n",
    "os.environ[\"FLASK_APP\"] = \"server.app\"\n",
    "os.environ[\"FLASK_ENV\"] = \"development\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run the flask app and lock the interpreter.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"server.app\" (lazy loading)\n",
      " * Environment: development\n",
      " * Debug mode: on\n",
      " * Running on http://0.0.0.0:8080/ (Press CTRL+C to quit)\n",
      " * Restarting with stat\n",
      " * Debugger is active!\n",
      " * Debugger PIN: 245-021-255\n",
      "127.0.0.1 - - [24/Oct/2020 14:38:04] \"\u001b[37mGET /frontend HTTP/1.1\u001b[0m\" 200 -\n",
      "      crim    zn  indus  chas    nox  ...  rad    tax  ptratio      b  lstat\n",
      "0  0.00632  18.0   2.31   0.0  0.538  ...  1.0  296.0     15.3  396.9   4.98\n",
      "\n",
      "[1 rows x 13 columns]\n",
      "making request\n",
      "prediciton [26.21]\n",
      "heylksdfmlsdmsdflklmsdfsdf\n",
      "127.0.0.1 - - [24/Oct/2020 14:38:06] \"\u001b[37mPOST /frontend HTTP/1.1\u001b[0m\" 200 -\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!cd ../src && python -m flask run --host 0.0.0.0 --port 8080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requests.request(\"POST\",\"http://localhost:6789/shutdown/\").json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'Detected REST server mode - this is an advanced option\\n',\n",
       " b'Detected /Users/timothy.whittaker/Desktop/ODSC/odsc-ml-drum/src/custom_model/custom.py .. trying to load hooks\\n',\n",
       " b'\\x1b[32m \\x1b[0m\\n',\n",
       " b'\\x1b[32m \\x1b[0m\\n',\n",
       " b'\\x1b[32m============================================================\\x1b[0m\\n',\n",
       " b'\\x1b[32mComponent: prediction_server\\x1b[0m\\n',\n",
       " b'\\x1b[32mLanguage:  Python\\x1b[0m\\n',\n",
       " b'\\x1b[32mOutput:\\x1b[0m\\n',\n",
       " b'\\x1b[32m------------------------------------------------------------\\x1b[0m\\n',\n",
       " b' * Serving Flask app \"datarobot_drum.drum.server\" (lazy loading)\\n',\n",
       " b' * Environment: production\\n',\n",
       " b'   WARNING: This is a development server. Do not use it in a production deployment.\\n',\n",
       " b'   Use a production WSGI server instead.\\n',\n",
       " b' * Debug mode: off\\n']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_server.terminate()\n",
    "inference_server.stdout.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitoring Deployments\n",
    "\n",
    "What follows will require a DataRobot account.  YOu can get a trial account at [https://www.datarobot.com/trial/](https://www.datarobot.com/trial/)\n",
    "\n",
    "The following will execute a script will do a lot of things.  Specifically\n",
    "* deploy the model package on datarobot which will be used for our external model\n",
    "* download agents service\n",
    "* configure and start up the agents service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading training data - ./data/boston_housing.csv. This may take some time...\n",
      "Training dataset uploaded. Catalog ID 5f94b867c35abe1be8b018f5.\n",
      "Create model package\n",
      "Deploy model package\n",
      "Enable feature drift\n",
      "\n",
      "Done.\n",
      "DEPLOYMENT_ID=5f94b88a75e84a30d5431c79, MODEL_ID=5f94b889678d7458b6e8ba10\n",
      "deployment details written to deployment_detail.yaml\n",
      "grab agents tarball\n",
      "unpack agents tarball\n",
      "configuring agents\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.2.4 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "INFO: AGENT_CONFIG_YAML=/Users/timothy.whittaker/Desktop/ODSC/odsc-ml-drum/datarobot-mlops-agent-6.2.4/conf/mlops.agent.conf.yaml\n",
      "INFO: AGENT_LOG_PROPERTIES=/Users/timothy.whittaker/Desktop/ODSC/odsc-ml-drum/datarobot-mlops-agent-6.2.4/conf/mlops.log4j2.properties\n",
      "INFO: AGENT_JVM_OPT=-Xmx1G\n",
      "INFO: AGENT_JAR_PATH=/Users/timothy.whittaker/Desktop/ODSC/odsc-ml-drum/datarobot-mlops-agent-6.2.4/lib/mlops-agent-6.2.4.jar\n",
      "INFO: AGENT_LOG_PATH=/Users/timothy.whittaker/Desktop/ODSC/odsc-ml-drum/datarobot-mlops-agent-6.2.4/logs/mlops.agent.log\n",
      "\n",
      "Starting MLOps-Agent\n",
      "\n",
      "\n",
      "DataRobot MLOps-Agent is running.\n"
     ]
    }
   ],
   "source": [
    "! cd .. && ./setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_sIji-jleSr"
   },
   "source": [
    "# Adding Monitoring with MLOps Monitoring Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring With DRUM\n",
    "\n",
    "There are a few addition parameters we should set for the command line utility, or we may just create environment variables, and allow the drum utility to pick up the details from there.  \n",
    "\n",
    "```\n",
    "  --monitor             Monitor predictions using DataRobot MLOps. True or\n",
    "                        False. (env: MONITOR).Monitoring can not be used in\n",
    "                        unstructured mode.\n",
    "  --deployment-id DEPLOYMENT_ID\n",
    "                        Deployment id to use for monitoring model predictions\n",
    "                        (env: DEPLOYMENT_ID)\n",
    "  --model-id MODEL_ID   MLOps model id to use for monitoring predictions (env:\n",
    "                        MODEL_ID)\n",
    "  --monitor-settings MONITOR_SETTINGS\n",
    "                        MLOps setting to use for connecting with the MLOps\n",
    "                        Agent (env: MONITOR_SETTINGS)\n",
    "```\n",
    "For today, we'll set environment variables to add monitoring. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../deployment_detail.yaml\", \"r\") as f:\n",
    "    dep_details = yaml.load(f, Loader = yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MONITOR\"] = \"True\"\n",
    "os.environ[\"DEPLOYMENT_ID\"] = dep_details[\"DEPLOYMENT_ID\"]\n",
    "os.environ[\"MODEL_ID\"] = dep_details[\"MODEL_ID\"]\n",
    "os.environ[\"MONITOR_SETTINGS\"] = \"spooler_type=filesystem;directory=/tmp/ta;max_files=5;file_max_size=1045876000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_server_with_monitoring = subprocess.Popen(run_inference_server, stdout=subprocess.PIPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"server.app\" (lazy loading)\n",
      " * Environment: development\n",
      " * Debug mode: on\n",
      " * Running on http://0.0.0.0:8080/ (Press CTRL+C to quit)\n",
      " * Restarting with stat\n",
      " * Debugger is active!\n",
      " * Debugger PIN: 245-021-255\n",
      "      crim    zn  indus  chas    nox  ...  rad    tax  ptratio      b  lstat\n",
      "0  0.00632  18.0   2.31   0.0  0.538  ...  2.0  296.0     12.1  396.9   4.98\n",
      "\n",
      "[1 rows x 13 columns]\n",
      "making request\n",
      "prediciton [26.5]\n",
      "heylksdfmlsdmsdflklmsdfsdf\n",
      "127.0.0.1 - - [24/Oct/2020 14:55:07] \"\u001b[37mPOST /frontend HTTP/1.1\u001b[0m\" 200 -\n",
      "      crim    zn  indus  chas    nox  ...  rad    tax  ptratio      b  lstat\n",
      "0  0.00632  18.0   2.31   0.0  0.538  ...  2.0  296.0     12.1  396.9   4.98\n",
      "\n",
      "[1 rows x 13 columns]\n",
      "making request\n",
      "prediciton [27.03]\n",
      "heylksdfmlsdmsdflklmsdfsdf\n",
      "127.0.0.1 - - [24/Oct/2020 14:55:11] \"\u001b[37mPOST /frontend HTTP/1.1\u001b[0m\" 200 -\n",
      "      crim    zn  indus  chas    nox  ...  rad    tax  ptratio      b  lstat\n",
      "0  0.00632  18.0   2.31   0.0  0.538  ...  2.0  350.0     12.1  396.9   4.98\n",
      "\n",
      "[1 rows x 13 columns]\n",
      "making request\n",
      "prediciton [27.25]\n",
      "heylksdfmlsdmsdflklmsdfsdf\n",
      "127.0.0.1 - - [24/Oct/2020 14:55:20] \"\u001b[37mPOST /frontend HTTP/1.1\u001b[0m\" 200 -\n",
      "      crim    zn  indus  chas    nox  ...  rad    tax  ptratio      b  lstat\n",
      "0  0.00632  18.0   2.31   0.0  0.538  ...  2.0  350.0     15.0  396.9   4.98\n",
      "\n",
      "[1 rows x 13 columns]\n",
      "making request\n",
      "prediciton [27.25]\n",
      "heylksdfmlsdmsdflklmsdfsdf\n",
      "127.0.0.1 - - [24/Oct/2020 14:55:26] \"\u001b[37mPOST /frontend HTTP/1.1\u001b[0m\" 200 -\n",
      "      crim    zn  indus  chas    nox  ...  rad    tax  ptratio      b  lstat\n",
      "0  0.00632  18.0   2.31   0.0  0.538  ...  2.0  350.0     15.0  396.9   4.98\n",
      "\n",
      "[1 rows x 13 columns]\n",
      "making request\n",
      "prediciton [26.81]\n",
      "heylksdfmlsdmsdflklmsdfsdf\n",
      "127.0.0.1 - - [24/Oct/2020 14:55:31] \"\u001b[37mPOST /frontend HTTP/1.1\u001b[0m\" 200 -\n",
      "      crim    zn  indus  chas    nox  ...  rad    tax  ptratio      b  lstat\n",
      "0  0.00632  18.0   2.31   0.0  0.538  ...  1.0  350.0     15.0  396.9   4.98\n",
      "\n",
      "[1 rows x 13 columns]\n",
      "making request\n",
      "prediciton [26.81]\n",
      "heylksdfmlsdmsdflklmsdfsdf\n",
      "127.0.0.1 - - [24/Oct/2020 14:55:35] \"\u001b[37mPOST /frontend HTTP/1.1\u001b[0m\" 200 -\n",
      "      crim    zn  indus  chas    nox  ...  rad    tax  ptratio      b  lstat\n",
      "0  0.00632  18.0   2.31   0.0  0.538  ...  1.0  350.0     15.0  396.9    6.0\n",
      "\n",
      "[1 rows x 13 columns]\n",
      "making request\n",
      "prediciton [27.07]\n",
      "heylksdfmlsdmsdflklmsdfsdf\n",
      "127.0.0.1 - - [24/Oct/2020 14:55:40] \"\u001b[37mPOST /frontend HTTP/1.1\u001b[0m\" 200 -\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!cd ../src && python -m flask run --host 0.0.0.0 --port 8080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.call(\"../{}/bin/stop-agent.sh\".format(agents_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'DataRobot MLOps-Agent is not running as a service.\\n']\n"
     ]
    }
   ],
   "source": [
    "## check that agent is stopped \n",
    "check = subprocess.Popen([\"../{}/bin/status-agent.sh\".format(agents_dir)], stdout=subprocess.PIPE)\n",
    "print(check.stdout.readlines())\n",
    "check.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = dr.Client(os.environ[\"TOKEN\"], os.path.join(os.environ[\"ENDPOINT\"], \"api/v2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "DataError",
     "evalue": "{'metrics': DataError({'executionTime': DataError({'value': DataError({0: DataError(value is not int), 1: DataError(value is not float)})}), 'responseTime': DataError({'value': DataError({0: DataError(value is not int), 1: DataError(value is not float)})})})}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-a03e175e674d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdeployment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDeployment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdep_details\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"DEPLOYMENT_ID\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdeployment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdeployment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_service_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/python_envs/odsc/lib/python3.7/site-packages/datarobot/models/deployment.py\u001b[0m in \u001b[0;36mget_service_stats\u001b[0;34m(self, model_id, start_time, end_time, execution_time_quantile, response_time_quantile, slow_requests_threshold)\u001b[0m\n\u001b[1;32m    886\u001b[0m             \u001b[0;34m'slow_requests_threshold'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslow_requests_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         }\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mServiceStats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m     def get_service_stats_over_time(self, metric=None, model_id=None, start_time=None,\n",
      "\u001b[0;32m~/python_envs/odsc/lib/python3.7/site-packages/datarobot/models/service_stats.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(cls, deployment_id, model_id, start_time, end_time, execution_time_quantile, response_time_quantile, slow_requests_threshold)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_null_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metrics'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python_envs/odsc/lib/python3.7/site-packages/datarobot/models/api_object.py\u001b[0m in \u001b[0;36mfrom_data\u001b[0;34m(cls, data)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfrom_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mchecked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_converter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0msafe_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filter_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchecked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msafe_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python_envs/odsc/lib/python3.7/site-packages/trafaret/base.py\u001b[0m in \u001b[0;36mcheck\u001b[0;34m(self, value, context)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \"\"\"\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'check_value'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python_envs/odsc/lib/python3.7/site-packages/trafaret/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, value, context)\u001b[0m\n\u001b[1;32m   1016\u001b[0m                         \u001b[0merrors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mde\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1018\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mDataError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrafaret\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1019\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcollect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDataError\u001b[0m: {'metrics': DataError({'executionTime': DataError({'value': DataError({0: DataError(value is not int), 1: DataError(value is not float)})}), 'responseTime': DataError({'value': DataError({0: DataError(value is not int), 1: DataError(value is not float)})})})}"
     ]
    }
   ],
   "source": [
    "deployment = dr.Deployment.get(dep_details[\"DEPLOYMENT_ID\"])\n",
    "deployment\n",
    "deployment.get_service_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_stats = deployment.get_service_stats()\n",
    "service_stats.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Custom Keras on GPU with DRUM and Monitoring Agent (DataRobot)",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
