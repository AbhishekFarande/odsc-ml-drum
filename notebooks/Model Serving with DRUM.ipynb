{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_nxQLKVeYTy"
   },
   "source": [
    "# Drum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drum 1.3.0\r\n"
     ]
    }
   ],
   "source": [
    "!drum --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4p0zDG-VWJP"
   },
   "source": [
    "# Test scoring with Sklearn model using DRUM\n",
    "<a id=\"setup_complete\"></a>\n",
    "\n",
    "Next snippet is to test scoring.  The functionality can also be used to do batch scoring with the model.  \n",
    "\n",
    "`../src/custom_model` contains the sklearn pkl as well as the `custom.py` file which contains hooks that allow DRUM to hook into our pkl.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "C_OOeqEx6hqH",
    "outputId": "89c75e87-d13f-4f3d-c5e9-dec4c7e696e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected score mode\n",
      "Detected /Users/timothy.whittaker/Desktop/ODSC/odsc-ml-drum/src/custom_model/custom.py .. trying to load hooks\n",
      "\u001b[32m \u001b[0m\n",
      "\u001b[32m \u001b[0m\n",
      "\u001b[32m============================================================\u001b[0m\n",
      "\u001b[32mComponent: generic_predictor\u001b[0m\n",
      "\u001b[32mLanguage:  Python\u001b[0m\n",
      "\u001b[32mOutput:\u001b[0m\n",
      "\u001b[32m------------------------------------------------------------\u001b[0m\n",
      "\u001b[32m------------------------------------------------------------\u001b[0m\n",
      "\u001b[32mRuntime:    0.0 sec\u001b[0m\n",
      "\u001b[32mNR outputs: 0\u001b[0m\n",
      "\u001b[32m============================================================\u001b[0m\n",
      "\u001b[32m \u001b[0m\n",
      "    Predictions\n",
      "0        26.210\n",
      "1        22.140\n",
      "2        34.930\n",
      "3        34.735\n",
      "4        35.200\n",
      "5        26.795\n",
      "6        20.985\n",
      "7        25.035\n",
      "8        18.205\n",
      "9        18.805\n",
      "10       16.365\n",
      "11       19.440\n",
      "12       21.695\n",
      "13       20.010\n",
      "14       18.400\n",
      "15       19.685\n",
      "16       22.185\n",
      "17       18.350\n",
      "18       19.790\n",
      "19       18.740\n"
     ]
    }
   ],
   "source": [
    "!drum score --code-dir ../src/custom_model --input ../data/boston_housing_test.csv --target-type regression --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JmS971iweH6t"
   },
   "source": [
    "# Start the inference server locally\n",
    "\n",
    "When starting the server, we'll use `subprocess.Popen` so we may interact with the server in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "D7BrHC1gYjHD"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "import yaml\n",
    "import time\n",
    "import os\n",
    "import datarobot as dr\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_inference_server = [\"drum\",\n",
    "              \"server\",\n",
    "              \"--code-dir\",\"../src/custom_model\", \n",
    "              \"--address\", \"0.0.0.0:6789\", \n",
    "              \"--show-perf\",\n",
    "              \"--target-type\", \"regression\",\n",
    "              \"--logging-level\", \"info\",\n",
    "              \"--show-stacktrace\",\n",
    "              \"--verbose\"\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "jWvksr_sYlEr"
   },
   "outputs": [],
   "source": [
    "inference_server = subprocess.Popen(run_inference_server, stdout=subprocess.PIPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "peFenY-leJo3"
   },
   "source": [
    "## Ping the Server to make sure it is running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "jmh7SRfQVnTU",
    "outputId": "0bc5161d-84dd-4c05-d0fe-0962f1c74c52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check status\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'{\"message\":\"OK\"}\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## confirm the server is running\n",
    "time.sleep(5) ## snoozing before pinging the server to give it time to actually start\n",
    "print('check status')\n",
    "requests.request(\"GET\", \"http://0.0.0.0:6789/\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Pb6ev0dkbGeX"
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/content/datarobot-user-models/tests/testdata/boston_housing_inference.csv')\n",
    "df = pd.read_csv('../data/boston_housing_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "iZ-sZcHMYmRx"
   },
   "outputs": [],
   "source": [
    "def score(data):\n",
    "    b_buf = BytesIO()\n",
    "    b_buf.write(data.to_csv(index=False).encode(\"utf-8\"))\n",
    "    b_buf.seek(0)\n",
    "  \n",
    "    url = \"http://localhost:6789/predict/\"\n",
    "    files = [\n",
    "        ('X', b_buf)\n",
    "    ]\n",
    "    response = requests.request(\"POST\", url, files = files, timeout=None, verify=False)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JOsaTgXOeNMG"
   },
   "source": [
    "## Send data to server for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "yBV2UffU748S",
    "outputId": "a7b4a9d7-a8ac-4dec-93c4-a79977fda402"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "        b  lstat  \n",
       "0  396.90   4.98  \n",
       "1  396.90   9.14  \n",
       "2  392.83   4.03  \n",
       "3  394.63   2.94  \n",
       "4  396.90   5.33  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "HjdKXUcUWUXq",
    "outputId": "5091625d-208d-4335-cfff-35d6449a6f2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [26.21,\n",
      "                 22.14,\n",
      "                 34.93,\n",
      "                 34.735,\n",
      "                 35.2,\n",
      "                 26.795,\n",
      "                 20.985,\n",
      "                 25.035,\n",
      "                 18.205,\n",
      "                 18.805,\n",
      "                 16.365,\n",
      "                 19.44,\n",
      "                 21.695,\n",
      "                 20.01,\n",
      "                 18.4,\n",
      "                 19.685,\n",
      "                 22.185,\n",
      "                 18.35,\n",
      "                 19.79,\n",
      "                 18.74]}\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "predictions = score(df).json() ## score entire dataset but only show first 5 records\n",
    "pprint(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26.795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20.985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18.205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16.365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>21.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>18.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>19.685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>22.185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18.740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    predictions\n",
       "0        26.210\n",
       "1        22.140\n",
       "2        34.930\n",
       "3        34.735\n",
       "4        35.200\n",
       "5        26.795\n",
       "6        20.985\n",
       "7        25.035\n",
       "8        18.205\n",
       "9        18.805\n",
       "10       16.365\n",
       "11       19.440\n",
       "12       21.695\n",
       "13       20.010\n",
       "14       18.400\n",
       "15       19.685\n",
       "16       22.185\n",
       "17       18.350\n",
       "18       19.790\n",
       "19       18.740"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the Flask App\n",
    "\n",
    "Set a few environment variables for the flask app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"LC_ALL\"] = \"C.UTF-8\"\n",
    "os.environ[\"LANG\"] = \"C.UTF-8\"\n",
    "os.environ[\"FLASK_APP\"] = \"server.app\"\n",
    "os.environ[\"FLASK_ENV\"] = \"development\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run the flask app and lock the interpreter.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"server.app\" (lazy loading)\n",
      " * Environment: development\n",
      " * Debug mode: on\n",
      " * Running on http://0.0.0.0:8080/ (Press CTRL+C to quit)\n",
      " * Restarting with stat\n",
      " * Debugger is active!\n",
      " * Debugger PIN: 245-021-255\n",
      "127.0.0.1 - - [24/Oct/2020 14:38:04] \"\u001b[37mGET /frontend HTTP/1.1\u001b[0m\" 200 -\n",
      "      crim    zn  indus  chas    nox  ...  rad    tax  ptratio      b  lstat\n",
      "0  0.00632  18.0   2.31   0.0  0.538  ...  1.0  296.0     15.3  396.9   4.98\n",
      "\n",
      "[1 rows x 13 columns]\n",
      "making request\n",
      "prediciton [26.21]\n",
      "heylksdfmlsdmsdflklmsdfsdf\n",
      "127.0.0.1 - - [24/Oct/2020 14:38:06] \"\u001b[37mPOST /frontend HTTP/1.1\u001b[0m\" 200 -\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!cd ../src && python -m flask run --host 0.0.0.0 --port 8080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requests.request(\"POST\",\"http://localhost:6789/shutdown/\").json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'Detected REST server mode - this is an advanced option\\n',\n",
       " b'Detected /Users/timothy.whittaker/Desktop/ODSC/odsc-ml-drum/src/custom_model/custom.py .. trying to load hooks\\n',\n",
       " b'\\x1b[32m \\x1b[0m\\n',\n",
       " b'\\x1b[32m \\x1b[0m\\n',\n",
       " b'\\x1b[32m============================================================\\x1b[0m\\n',\n",
       " b'\\x1b[32mComponent: prediction_server\\x1b[0m\\n',\n",
       " b'\\x1b[32mLanguage:  Python\\x1b[0m\\n',\n",
       " b'\\x1b[32mOutput:\\x1b[0m\\n',\n",
       " b'\\x1b[32m------------------------------------------------------------\\x1b[0m\\n',\n",
       " b' * Serving Flask app \"datarobot_drum.drum.server\" (lazy loading)\\n',\n",
       " b' * Environment: production\\n',\n",
       " b'   WARNING: This is a development server. Do not use it in a production deployment.\\n',\n",
       " b'   Use a production WSGI server instead.\\n',\n",
       " b' * Debug mode: off\\n']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_server.terminate()\n",
    "inference_server.stdout.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitoring Deployments\n",
    "\n",
    "What follows will require a DataRobot account.  YOu can get a trial account at [https://www.datarobot.com/trial/](https://www.datarobot.com/trial/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the monitoring agents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = os.environ[\"DATAROBOT_API_TOKEN\"]\n",
    "endpoint = \"https://app.datarobot.com\"\n",
    "## connect to DataRobot platform with python client. \n",
    "client = dr.Client(token, \"{}/api/v2\".format(endpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlops_agents_tb = client.get(\"mlopsInstaller\")\n",
    "with open(\"../mlops-agent.tar.gz\", \"wb\") as f:\n",
    "    f.write(mlops_agents_tb.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xf ../mlops-agent.tar.gz -C .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datarobot-mlops-agent-6.2.4\n"
     ]
    }
   ],
   "source": [
    "agents_dir = next(filter(lambda x: \"datarobot-mlops\" in x, os.listdir(\"..\")))\n",
    "print(agents_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timothy.whittaker/python_envs/odsc/lib/python3.7/site-packages/ipykernel_launcher.py:2: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mlopsUrl': 'https://<DATAROBOT_HOST>',\n",
       " 'apiToken': 'FILL_IN_HERE',\n",
       " 'runOnce': False,\n",
       " 'dryRun': False,\n",
       " 'logPath': './logs/mlops.agent.log',\n",
       " 'statsPath': '/tmp/tracking-agent-stats.json',\n",
       " 'httpRetry': 1,\n",
       " 'httpTimeout': 30000,\n",
       " 'channelConfigs': [{'type': 'FS_SPOOL',\n",
       "   'details': {'name': 'filesystem', 'directory': '/tmp/ta'}}],\n",
       " 'agentThreadPoolSize': 4,\n",
       " 'agentMaxRecordsTask': 100,\n",
       " 'agentMaxAggregatedRecords': 500,\n",
       " 'agentPendingRecordsTimeoutMs': 2500}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(r'../{}/conf/mlops.agent.conf.yaml'.format(agents_dir)) as file:\n",
    "    documents = yaml.load(file)\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents['mlopsUrl'] = \"https://app.datarobot.com\"\n",
    "# Set your API token\n",
    "documents['apiToken'] = token\n",
    "with open('../{}/conf/mlops.agent.conf.yaml'.format(agents_dir), \"w\") as f:\n",
    "    yaml.dump(documents, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the spooler filesystem location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /tmp/ta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Agent Service\n",
    "\n",
    "Checking to make sure we can start up the agents service.  \n",
    "\n",
    "This will require a JDK - tested with 11 and 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## run agents service\n",
    "subprocess.call(\"../{}/bin/start-agent.sh\".format(agents_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'DataRobot MLOps-Agent is running as a service.\\n']\n"
     ]
    }
   ],
   "source": [
    "## check status\n",
    "check = subprocess.Popen([\"../{}/bin/status-agent.sh\".format(agents_dir)], stdout=subprocess.PIPE)\n",
    "print(check.stdout.readlines())\n",
    "check.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'2020-10-24 14:44:54,254 INFO  com.datarobot.mlops.agent.config.channels.YamlBuilder        [] - Found spooler of type FILESYSTEM\\n'\n",
      "b'2020-10-24 14:44:54,256 INFO  com.datarobot.mlops.agent.config.channels.YamlBuilder        [] - Setting directory = /tmp/ta\\n'\n",
      "b'2020-10-24 14:44:54,257 INFO  com.datarobot.mlops.agent.config.channels.YamlBuilder        [] - Setting CHANNEL_NAME = filesystem\\n'\n",
      "b\"2020-10-24 14:44:55,226 INFO  com.datarobot.mlops.common.client.MLOpsClient                [] - DataRobot Server API Version found: '2.23.0'\\n\"\n",
      "b\"2020-10-24 14:44:55,355 INFO  com.datarobot.mlops.common.client.MLOpsClient                [] - DataRobot Server API Version found: '2.23.0'\\n\"\n",
      "b\"2020-10-24 14:44:55,355 INFO  com.datarobot.mlops.agent.Agent                              [] - DataRobot server at 'https://app.datarobot.com' is reachable.\\n\"\n",
      "b'2020-10-24 14:44:55,355 INFO  com.datarobot.mlops.agent.Agent                              [] - DataRobot Monitoring Agent will process 100 records at a time at most.\\n'\n",
      "b'2020-10-24 14:44:55,357 INFO  com.datarobot.mlops.agent.AgentRunner                        [] - Creating new agent channel\\n'\n",
      "b'2020-10-24 14:44:55,358 INFO  com.datarobot.mlops.agent.AgentRunner                        [] - Initializing agent channel\\n'\n",
      "b'2020-10-24 14:44:55,378 INFO  com.datarobot.mlops.agent.AgentRunner                        [] - Initialized\\n'\n",
      "b'2020-10-24 14:44:55,379 INFO  com.datarobot.mlops.agent.AgentRunner                        [] - Listing channels:\\n'\n",
      "b'\\tChannel Name: filesystem, Channel Type: FILESYSTEM\\n'\n",
      "b'\\n'\n",
      "b'2020-10-24 14:44:55,380 INFO  com.datarobot.mlops.agent.AgentRunner                        [] - Running agent as service process pid and hostname [10675@twhittaker-mb-G0ZUH]\\n'\n",
      "b'2020-10-24 14:52:52,167 INFO  com.datarobot.mlops.agent.AgentRunner                        [] - MLOps agent runner shutdown in progress...\\n'\n",
      "b'2020-10-24 14:53:38,079 INFO  com.datarobot.mlops.agent.config.channels.YamlBuilder        [] - Found spooler of type FILESYSTEM\\n'\n",
      "b'2020-10-24 14:53:38,083 INFO  com.datarobot.mlops.agent.config.channels.YamlBuilder        [] - Setting directory = /tmp/ta\\n'\n",
      "b'2020-10-24 14:53:38,083 INFO  com.datarobot.mlops.agent.config.channels.YamlBuilder        [] - Setting CHANNEL_NAME = filesystem\\n'\n",
      "b\"2020-10-24 14:53:38,756 INFO  com.datarobot.mlops.common.client.MLOpsClient                [] - DataRobot Server API Version found: '2.23.0'\\n\"\n",
      "b\"2020-10-24 14:53:38,885 INFO  com.datarobot.mlops.common.client.MLOpsClient                [] - DataRobot Server API Version found: '2.23.0'\\n\"\n",
      "b\"2020-10-24 14:53:38,885 INFO  com.datarobot.mlops.agent.Agent                              [] - DataRobot server at 'https://app.datarobot.com' is reachable.\\n\"\n",
      "b'2020-10-24 14:53:38,886 INFO  com.datarobot.mlops.agent.Agent                              [] - DataRobot Monitoring Agent will process 100 records at a time at most.\\n'\n",
      "b'2020-10-24 14:53:38,887 INFO  com.datarobot.mlops.agent.AgentRunner                        [] - Creating new agent channel\\n'\n",
      "b'2020-10-24 14:53:38,887 INFO  com.datarobot.mlops.agent.AgentRunner                        [] - Initializing agent channel\\n'\n",
      "b'2020-10-24 14:53:38,926 INFO  com.datarobot.mlops.agent.AgentRunner                        [] - Initialized\\n'\n",
      "b'2020-10-24 14:53:38,927 INFO  com.datarobot.mlops.agent.AgentRunner                        [] - Listing channels:\\n'\n",
      "b'\\tChannel Name: filesystem, Channel Type: FILESYSTEM\\n'\n",
      "b'\\n'\n",
      "b'2020-10-24 14:53:38,928 INFO  com.datarobot.mlops.agent.AgentRunner                        [] - Running agent as service process pid and hostname [10981@twhittaker-mb-G0ZUH]\\n'\n"
     ]
    }
   ],
   "source": [
    "## check log to see that the agent connected to DR MLOps\n",
    "check = subprocess.Popen([\"cat\", \"../{}/logs/mlops.agent.log\".format(agents_dir)], stdout=subprocess.PIPE)\n",
    "for line in check.stdout.readlines():\n",
    "    print(line)\n",
    "check.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataRobot MLOps - Deploying External Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To communication with DataRobot MLOps, with need to MLOps python client installed which came in the downloaded tarball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.2.4 is available.\r\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ../datarobot-mlops-*/lib/datarobot_mlops-*.whl -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datarobot.mlops.mlops import MLOps\n",
    "from datarobot.mlops.common.enums import OutputType\n",
    "from datarobot.mlops.connected.client import MLOpsClient\n",
    "from datarobot.mlops.common.exception import DRConnectedException\n",
    "from datarobot.mlops.constants import Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPLOYMENT_NAME=\"Boston Housing Prices ODSC\"\n",
    "TRAINING_DATA = '../data/boston_housing.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info = {\n",
    "        \"name\": \"Boston Housing Pricins\",\n",
    "        \"modelDescription\": {\n",
    "            \"description\": \"prediction price of home\"\n",
    "        },\n",
    "        \"target\": {\n",
    "            \"type\": \"Regression\",\n",
    "            \"name\": \"medv\",\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading training data - ../data/boston_housing.csv. This may take some time...\n",
      "Training dataset uploaded. Catalog ID 5f9476cdcc86ae1bda8032f2.\n",
      "Create model package\n",
      "Deploy model package\n",
      "Enable feature drift\n",
      "\n",
      "Done.\n",
      "DEPLOYMENT_ID=5f94770475e84a30c542f0d5, MODEL_ID=5f947703678d745770e8bbf7\n"
     ]
    }
   ],
   "source": [
    "# Create connected client\n",
    "mlops_client = MLOpsClient(\"https://app.datarobot.com\", token)\n",
    "\n",
    "# Add training_data to model configuration\n",
    "print(\"Uploading training data - {}. This may take some time...\".format(TRAINING_DATA))\n",
    "dataset_id = mlops_client.upload_dataset(TRAINING_DATA)\n",
    "print(\"Training dataset uploaded. Catalog ID {}.\".format(dataset_id))\n",
    "model_info[\"datasets\"] = {\"trainingDataCatalogId\": dataset_id}\n",
    "\n",
    "# Create the model package\n",
    "print('Create model package')\n",
    "model_pkg_id = mlops_client.create_model_package(model_info)\n",
    "model_pkg = mlops_client.get_model_package(model_pkg_id)\n",
    "model_id = model_pkg[\"modelId\"]\n",
    "\n",
    "# Deploy the model package\n",
    "print('Deploy model package')\n",
    "deployment_id = mlops_client.deploy_model_package(model_pkg[\"id\"],\n",
    "                                                            DEPLOYMENT_NAME)\n",
    "\n",
    "# Enable data drift tracking\n",
    "print('Enable feature drift')\n",
    "enable_feature_drift = TRAINING_DATA is not None\n",
    "mlops_client.update_deployment_settings(deployment_id, target_drift=True,\n",
    "                                                  feature_drift=enable_feature_drift)\n",
    "_ = mlops_client.get_deployment_settings(deployment_id)\n",
    "\n",
    "print(\"\\nDone.\")\n",
    "print(\"DEPLOYMENT_ID=%s, MODEL_ID=%s\" % (deployment_id, model_id))\n",
    "\n",
    "DEPLOYMENT_ID = deployment_id\n",
    "MODEL_ID = model_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_sIji-jleSr"
   },
   "source": [
    "# Adding Monitoring with MLOps Monitoring Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring With DRUM\n",
    "\n",
    "There are a few addition parameters we should set for the command line utility, or we may just create environment variables, and allow the drum utility to pick up the details from there.  \n",
    "\n",
    "```\n",
    "  --monitor             Monitor predictions using DataRobot MLOps. True or\n",
    "                        False. (env: MONITOR).Monitoring can not be used in\n",
    "                        unstructured mode.\n",
    "  --deployment-id DEPLOYMENT_ID\n",
    "                        Deployment id to use for monitoring model predictions\n",
    "                        (env: DEPLOYMENT_ID)\n",
    "  --model-id MODEL_ID   MLOps model id to use for monitoring predictions (env:\n",
    "                        MODEL_ID)\n",
    "  --monitor-settings MONITOR_SETTINGS\n",
    "                        MLOps setting to use for connecting with the MLOps\n",
    "                        Agent (env: MONITOR_SETTINGS)\n",
    "```\n",
    "For today, we'll set environment variables to add monitoring. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MONITOR\"] = \"True\"\n",
    "os.environ[\"DEPLOYMENT_ID\"] = deployment_id\n",
    "os.environ[\"MODEL_ID\"] = model_id\n",
    "os.environ[\"MONITOR_SETTINGS\"] = \"spooler_type=filesystem;directory=/tmp/ta;max_files=5;file_max_size=1045876000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_server_with_monitoring = subprocess.Popen(run_inference_server, stdout=subprocess.PIPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"server.app\" (lazy loading)\n",
      " * Environment: development\n",
      " * Debug mode: on\n",
      " * Running on http://0.0.0.0:8080/ (Press CTRL+C to quit)\n",
      " * Restarting with stat\n",
      " * Debugger is active!\n",
      " * Debugger PIN: 245-021-255\n",
      "      crim    zn  indus  chas    nox  ...  rad    tax  ptratio      b  lstat\n",
      "0  0.00632  18.0   2.31   0.0  0.538  ...  2.0  296.0     12.1  396.9   4.98\n",
      "\n",
      "[1 rows x 13 columns]\n",
      "making request\n",
      "prediciton [26.5]\n",
      "heylksdfmlsdmsdflklmsdfsdf\n",
      "127.0.0.1 - - [24/Oct/2020 14:55:07] \"\u001b[37mPOST /frontend HTTP/1.1\u001b[0m\" 200 -\n",
      "      crim    zn  indus  chas    nox  ...  rad    tax  ptratio      b  lstat\n",
      "0  0.00632  18.0   2.31   0.0  0.538  ...  2.0  296.0     12.1  396.9   4.98\n",
      "\n",
      "[1 rows x 13 columns]\n",
      "making request\n",
      "prediciton [27.03]\n",
      "heylksdfmlsdmsdflklmsdfsdf\n",
      "127.0.0.1 - - [24/Oct/2020 14:55:11] \"\u001b[37mPOST /frontend HTTP/1.1\u001b[0m\" 200 -\n",
      "      crim    zn  indus  chas    nox  ...  rad    tax  ptratio      b  lstat\n",
      "0  0.00632  18.0   2.31   0.0  0.538  ...  2.0  350.0     12.1  396.9   4.98\n",
      "\n",
      "[1 rows x 13 columns]\n",
      "making request\n",
      "prediciton [27.25]\n",
      "heylksdfmlsdmsdflklmsdfsdf\n",
      "127.0.0.1 - - [24/Oct/2020 14:55:20] \"\u001b[37mPOST /frontend HTTP/1.1\u001b[0m\" 200 -\n",
      "      crim    zn  indus  chas    nox  ...  rad    tax  ptratio      b  lstat\n",
      "0  0.00632  18.0   2.31   0.0  0.538  ...  2.0  350.0     15.0  396.9   4.98\n",
      "\n",
      "[1 rows x 13 columns]\n",
      "making request\n",
      "prediciton [27.25]\n",
      "heylksdfmlsdmsdflklmsdfsdf\n",
      "127.0.0.1 - - [24/Oct/2020 14:55:26] \"\u001b[37mPOST /frontend HTTP/1.1\u001b[0m\" 200 -\n",
      "      crim    zn  indus  chas    nox  ...  rad    tax  ptratio      b  lstat\n",
      "0  0.00632  18.0   2.31   0.0  0.538  ...  2.0  350.0     15.0  396.9   4.98\n",
      "\n",
      "[1 rows x 13 columns]\n",
      "making request\n",
      "prediciton [26.81]\n",
      "heylksdfmlsdmsdflklmsdfsdf\n",
      "127.0.0.1 - - [24/Oct/2020 14:55:31] \"\u001b[37mPOST /frontend HTTP/1.1\u001b[0m\" 200 -\n",
      "      crim    zn  indus  chas    nox  ...  rad    tax  ptratio      b  lstat\n",
      "0  0.00632  18.0   2.31   0.0  0.538  ...  1.0  350.0     15.0  396.9   4.98\n",
      "\n",
      "[1 rows x 13 columns]\n",
      "making request\n",
      "prediciton [26.81]\n",
      "heylksdfmlsdmsdflklmsdfsdf\n",
      "127.0.0.1 - - [24/Oct/2020 14:55:35] \"\u001b[37mPOST /frontend HTTP/1.1\u001b[0m\" 200 -\n",
      "      crim    zn  indus  chas    nox  ...  rad    tax  ptratio      b  lstat\n",
      "0  0.00632  18.0   2.31   0.0  0.538  ...  1.0  350.0     15.0  396.9    6.0\n",
      "\n",
      "[1 rows x 13 columns]\n",
      "making request\n",
      "prediciton [27.07]\n",
      "heylksdfmlsdmsdflklmsdfsdf\n",
      "127.0.0.1 - - [24/Oct/2020 14:55:40] \"\u001b[37mPOST /frontend HTTP/1.1\u001b[0m\" 200 -\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!cd ../src && python -m flask run --host 0.0.0.0 --port 8080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.call(\"../{}/bin/stop-agent.sh\".format(agents_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'DataRobot MLOps-Agent is not running as a service.\\n']\n"
     ]
    }
   ],
   "source": [
    "## check that agent is stopped \n",
    "check = subprocess.Popen([\"../{}/bin/status-agent.sh\".format(agents_dir)], stdout=subprocess.PIPE)\n",
    "print(check.stdout.readlines())\n",
    "check.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ServiceStats(5f947703678d745770e8bbf7 | 2020-10-17 19:00:00+00:00 - 2020-10-24 19:00:00+00:00)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployment = dr.Deployment.get(deployment_id)\n",
    "deployment\n",
    "deployment.get_service_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'totalPredictions': 6,\n",
       " 'userErrorRate': 0,\n",
       " 'cacheHitRatio': 0,\n",
       " 'executionTime': 8.88895988464355,\n",
       " 'totalRequests': 6,\n",
       " 'serverErrorRate': 0,\n",
       " 'slowRequests': 0,\n",
       " 'medianLoad': 0,\n",
       " 'numConsumers': 1,\n",
       " 'responseTime': 0,\n",
       " 'peakLoad': 6}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service_stats = deployment.get_service_stats()\n",
    "service_stats.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Custom Keras on GPU with DRUM and Monitoring Agent (DataRobot)",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
