{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Brief Tour of DRUM.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IzhGAhUajyp"
      },
      "source": [
        "# DRUM\n",
        "\n",
        "About [DRUM](https://github.com/datarobot/datarobot-user-models/tree/master/custom_model_runner)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqlULeRiamIg",
        "outputId": "da5ccefe-2a54-4138-ed69-56ad82b78a81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%pip install datarobot-drum"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting datarobot-drum\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/8a/ccec30cf635d36ba2bc416ddb061dc8106960c16ab71d0b07202d0de1851/datarobot_drum-1.4.1-py3-none-any.whl (8.7MB)\n",
            "\u001b[K     |████████████████████████████████| 8.7MB 3.8MB/s \n",
            "\u001b[?25hCollecting docker>=4.2.2<5.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/8c/8d42dbd83679483db207535f4fb02dc84325fa78b290f057694b057fcd21/docker-4.3.1-py2.py3-none-any.whl (145kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 46.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from datarobot-drum) (2.23.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from datarobot-drum) (2.11.2)\n",
            "Collecting argcomplete==1.11.1\n",
            "  Downloading https://files.pythonhosted.org/packages/82/7d/455e149c28c320044cb763c23af375bd77d52baca041f611f5c2b4865cf4/argcomplete-1.11.1-py2.py3-none-any.whl\n",
            "Collecting mlpiper~=2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/32/4f8980d93031f58af0517f7b64cb1eaa3431a0e2a87fe51534ef2b9de168/mlpiper-2.3.3-py2.py3-none-any.whl (781kB)\n",
            "\u001b[K     |████████████████████████████████| 788kB 47.7MB/s \n",
            "\u001b[?25hCollecting strictyaml==1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/97/e8e62cc00aafc52aeffc7cbe3f90d15f8edd4bfe539346fe7eb505a7e1b8/strictyaml-1.0.6.tar.gz (47kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.4MB/s \n",
            "\u001b[?25hCollecting datarobot==2.21.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/52/af0a431d93aefc377a5c9ff467e064068bb85a5fc8edfd0de0c2cb1528e0/datarobot-2.21.3-py3-none-any.whl (266kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 44.1MB/s \n",
            "\u001b[?25hCollecting py4j~=0.10.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/42/25ad191f311fcdb38b750d49de167abd535e37a144e730a80d7c439d1751/py4j-0.10.9.1-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 47.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from datarobot-drum) (1.1.3)\n",
            "Collecting progress\n",
            "  Downloading https://files.pythonhosted.org/packages/38/ef/2e887b3d2b248916fc2121889ce68af8a16aaddbe82f9ae6533c24ff0d2b/progress-1.5.tar.gz\n",
            "Collecting memory-profiler<1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/8f/fd/d92b3295657f8837e0177e7b48b32d6651436f0293af42b76d134c3bb489/memory_profiler-0.58.0.tar.gz\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.6/dist-packages (from datarobot-drum) (1.1.2)\n",
            "Collecting texttable\n",
            "  Downloading https://files.pythonhosted.org/packages/06/f5/46201c428aebe0eecfa83df66bf3e6caa29659dbac5a56ddfd83cae0d4a4/texttable-1.6.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: scipy<2,>=1.1 in /usr/local/lib/python3.6/dist-packages (from datarobot-drum) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from datarobot-drum) (1.18.5)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from docker>=4.2.2<5.0.0->datarobot-drum) (1.15.0)\n",
            "Collecting websocket-client>=0.32.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 39.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->datarobot-drum) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->datarobot-drum) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->datarobot-drum) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->datarobot-drum) (2.10)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->datarobot-drum) (1.1.1)\n",
            "Collecting importlib-metadata<2,>=0.23; python_version == \"3.6\"\n",
            "  Downloading https://files.pythonhosted.org/packages/8e/58/cdea07eb51fc2b906db0968a94700866fc46249bdc75cac23f9d13168929/importlib_metadata-1.7.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from mlpiper~=2.3.0->datarobot-drum) (5.4.8)\n",
            "Collecting flask-cors\n",
            "  Downloading https://files.pythonhosted.org/packages/69/7f/d0aeaaafb5c3c76c8d2141dbe2d4f6dca5d6c31872d4e5349768c1958abc/Flask_Cors-3.0.9-py2.py3-none-any.whl\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from mlpiper~=2.3.0->datarobot-drum) (1.1.0)\n",
            "Collecting uwsgi; sys_platform != \"win32\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/75/45234f7b441c59b1eefd31ba3d1041a7e3c89602af24488e2a22e11e7259/uWSGI-2.0.19.1.tar.gz (803kB)\n",
            "\u001b[K     |████████████████████████████████| 808kB 39.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from mlpiper~=2.3.0->datarobot-drum) (0.16.0)\n",
            "Collecting ruamel.yaml>=0.14.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/39/186f14f3836ac5d2a6a042c8de69988770e8b9abb537610edc429e4914aa/ruamel.yaml-0.16.12-py2.py3-none-any.whl (111kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 32.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from strictyaml==1.0.6->datarobot-drum) (2.8.1)\n",
            "Requirement already satisfied: contextlib2>=0.5.5 in /usr/local/lib/python3.6/dist-packages (from datarobot==2.21.3->datarobot-drum) (0.5.5)\n",
            "Collecting attrs<20.0,>=19.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a2/db/4313ab3be961f7a763066401fb77f7748373b6094076ae2bda2806988af6/attrs-19.3.0-py2.py3-none-any.whl\n",
            "Collecting trafaret!=1.1.0,<2.0,>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/02/59/b502446f3985a9351ea4bfca4e90471668206d3a957e5e2ea256fc3d9d35/trafaret-1.2.0-py3-none-any.whl\n",
            "Collecting requests-toolbelt>=0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/ef/7681134338fc097acef8d9b2f8abe0458e4d87559c689a8c306d0957ece5/requests_toolbelt-0.9.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=3.11 in /usr/local/lib/python3.6/dist-packages (from datarobot==2.21.3->datarobot-drum) (3.13)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->datarobot-drum) (2018.9)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask->datarobot-drum) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from flask->datarobot-drum) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask->datarobot-drum) (1.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata<2,>=0.23; python_version == \"3.6\"->argcomplete==1.11.1->datarobot-drum) (3.3.1)\n",
            "Collecting ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.9\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/ff/ec25dc01ef04232a9e68ff18492e37dfa01f1f58172e702ad4f38536d41b/ruamel.yaml.clib-0.2.2-cp36-cp36m-manylinux1_x86_64.whl (549kB)\n",
            "\u001b[K     |████████████████████████████████| 552kB 42.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: strictyaml, progress, memory-profiler, uwsgi\n",
            "  Building wheel for strictyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for strictyaml: filename=strictyaml-1.0.6-cp36-none-any.whl size=25273 sha256=ede722fea663214375a875992061e0788917ef382405d6cee628dbeedf48e860\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/db/4d/deb821b0efddef300d0788a44daa2fd5cefd886789ab8e0027\n",
            "  Building wheel for progress (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for progress: filename=progress-1.5-cp36-none-any.whl size=8074 sha256=57211110f90dcfb83ec24e70f0ec1cf5e41dd24a63a42b38201269cb73ce4cae\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/c8/80/32a294e3041f006c661838c05a411c7b7ffc60ff939d14e116\n",
            "  Building wheel for memory-profiler (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for memory-profiler: filename=memory_profiler-0.58.0-cp36-none-any.whl size=30181 sha256=3e2dce6fa9453c57d1b4c2b4cc979237c1acff033f60e65a209ac345be9784f2\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/e4/0b/aaab481fc5dd2a4ea59e78bc7231bb6aae7635ca7ee79f8ae5\n",
            "  Building wheel for uwsgi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for uwsgi: filename=uWSGI-2.0.19.1-cp36-cp36m-linux_x86_64.whl size=597483 sha256=58c9ad21d09278020e5509ae9122c1d5938b8b08ba3542062b07ee0356c1378f\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/71/3d/24020be7a7ea936a375cf6144285eb3b5a5ed79cc694f247c0\n",
            "Successfully built strictyaml progress memory-profiler uwsgi\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: websocket-client, docker, importlib-metadata, argcomplete, flask-cors, py4j, uwsgi, mlpiper, ruamel.yaml.clib, ruamel.yaml, strictyaml, attrs, trafaret, requests-toolbelt, datarobot, progress, memory-profiler, texttable, datarobot-drum\n",
            "  Found existing installation: importlib-metadata 2.0.0\n",
            "    Uninstalling importlib-metadata-2.0.0:\n",
            "      Successfully uninstalled importlib-metadata-2.0.0\n",
            "  Found existing installation: attrs 20.2.0\n",
            "    Uninstalling attrs-20.2.0:\n",
            "      Successfully uninstalled attrs-20.2.0\n",
            "Successfully installed argcomplete-1.11.1 attrs-19.3.0 datarobot-2.21.3 datarobot-drum-1.4.1 docker-4.3.1 flask-cors-3.0.9 importlib-metadata-1.7.0 memory-profiler-0.58.0 mlpiper-2.3.3 progress-1.5 py4j-0.10.9.1 requests-toolbelt-0.9.1 ruamel.yaml-0.16.12 ruamel.yaml.clib-0.2.2 strictyaml-1.0.6 texttable-1.6.3 trafaret-1.2.0 uwsgi-2.0.19.1 websocket-client-0.57.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FD0EgjpQatZ2",
        "outputId": "02724869-321e-4dc8-bd18-3f0047bac695",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/timsetsfire/odsc-ml-drum.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'odsc-ml-drum'...\n",
            "remote: Enumerating objects: 185, done.\u001b[K\n",
            "remote: Counting objects: 100% (185/185), done.\u001b[K\n",
            "remote: Compressing objects: 100% (156/156), done.\u001b[K\n",
            "remote: Total 357 (delta 85), reused 77 (delta 27), pack-reused 172\u001b[K\n",
            "Receiving objects: 100% (357/357), 77.61 MiB | 31.93 MiB/s, done.\n",
            "Resolving deltas: 100% (152/152), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhf2wEYSajys"
      },
      "source": [
        "```\n",
        "usage: drum [-h] [--version]\n",
        "            {score,fit,perf-test,validation,server,new,push} ...\n",
        "\n",
        "Run user model\n",
        "\n",
        "positional arguments:\n",
        "  {score,fit,perf-test,validation,server,new,push}\n",
        "                        Commands\n",
        "    score               Run predictions in batch mode\n",
        "    fit                 Fit your model to your data\n",
        "    perf-test           Run performance tests\n",
        "    validation          Run validation checks\n",
        "    server              Run predictions in server\n",
        "    new                 Create new model/env template\n",
        "    push                Add your modeling code into DataRobot\n",
        "\n",
        "optional arguments:\n",
        "  -h, --help            show this help message and exit\n",
        "  --version             show program's version number and exit\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tyqxh3D1ajyt"
      },
      "source": [
        "## Help"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjW2OHdXajyt",
        "outputId": "0bd7c52a-ca4f-4fc8-8ecf-b844d8ac973f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!drum --help"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: drum [-h] [--version]\n",
            "            {score,fit,perf-test,validation,server,new,push} ...\n",
            "\n",
            "Run user model\n",
            "\n",
            "positional arguments:\n",
            "  {score,fit,perf-test,validation,server,new,push}\n",
            "                        Commands\n",
            "    score               Run predictions in batch mode\n",
            "    fit                 Fit your model to your data\n",
            "    perf-test           Run performance tests\n",
            "    validation          Run validation checks\n",
            "    server              Run predictions in server\n",
            "    new                 Create new model/env template\n",
            "    push                Add your modeling code into DataRobot\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --version             show program's version number and exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zP7vTBHZajyy"
      },
      "source": [
        "## New"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJr3bi9_ajyy",
        "outputId": "f7705b2e-2488-4d12-bee7-9a3fdcd69383",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!drum new -h"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: drum new [-h] [--verbose]\n",
            "                [--logging-level {noset,debug,info,warn,warning,error,critical}]\n",
            "                {model} ...\n",
            "\n",
            "Create new model/env template\n",
            "\n",
            "positional arguments:\n",
            "  {model}               Commands\n",
            "    model               Create a new modeling code directory template\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --verbose             Show verbose output\n",
            "  --logging-level {noset,debug,info,warn,warning,error,critical}\n",
            "                        Logging level to use\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQkkJ2bzajy2"
      },
      "source": [
        "Create a new template where you will place model artifacts.  This will generate a custom.py file to aid in adding hooks for you model if necessary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHx7HVZ8a-Vs",
        "outputId": "6993cc7b-ec4e-4037-ac6f-e24d83b3256e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls -l odsc-ml-drum"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 428\n",
            "-rw-r--r-- 1 root root     69 Nov  3 18:43  colab-requirements.txt\n",
            "-rw-r--r-- 1 root root  76642 Nov  3 18:43 'Colab Version DRUM Model Serving Made Easy.ipynb'\n",
            "-rw-r--r-- 1 root root 334744 Nov  3 18:43 'Custom_Keras_on_GPU_with_DRUM_and_Monitoring_Agent_(DataRobot).ipynb'\n",
            "drwxr-xr-x 2 root root   4096 Nov  3 18:43  data\n",
            "drwxr-xr-x 3 root root   4096 Nov  3 18:43  notebooks\n",
            "-rw-r--r-- 1 root root   1696 Nov  3 18:43  README.md\n",
            "-rwxr-xr-x 1 root root   2332 Nov  3 18:43  requirements.txt\n",
            "drwxr-xr-x 5 root root   4096 Nov  3 18:43  src\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0wS9hpIajy2",
        "outputId": "81595aa6-752f-4efc-e613-e6201e7d0e56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!drum new model --code-dir odsc-ml-drum/src/other_models/drum-fit-model  --language python --verbose --logging-level debug"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Detected template generation mode\n",
            "2020-11-03 18:45:42,175 DEBUG drum.CMTemplateGenerator:  templates_dir: /usr/local/lib/python3.6/dist-packages/datarobot_drum/drum/../resource/templates\n",
            "2020-11-03 18:45:42,175 DEBUG drum.CMTemplateGenerator:  lang: RunLanguage.PYTHON\n",
            "2020-11-03 18:45:42,175 DEBUG drum.CMTemplateGenerator:  Templates are at: /usr/local/lib/python3.6/dist-packages/datarobot_drum/drum/../resource/templates\n",
            "2020-11-03 18:45:42,175 DEBUG drum.CMTemplateGenerator:  vars: {'custom_name': 'custom.py',\n",
            " 'gen_command': 'drum new model --language python',\n",
            " 'gen_date': 'Tue Nov  3 18:45:42 2020'}\n",
            "2020-11-03 18:45:42,181 DEBUG drum.CMTemplateGenerator:  src: /usr/local/lib/python3.6/dist-packages/datarobot_drum/drum/../resource/templates/custom_python_template.py.j2 dst:/content/odsc-ml-drum/src/other_models/drum-fit-model/custom.py\n",
            "2020-11-03 18:45:42,181 DEBUG drum.CMTemplateGenerator:  vars: {'custom_name': 'custom.py',\n",
            " 'gen_command': 'drum new model --language python',\n",
            " 'gen_date': 'Tue Nov  3 18:45:42 2020'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEitzYTXajy5"
      },
      "source": [
        "## Fit\n",
        "\n",
        "Fit mode\n",
        "\n",
        "Note: Running fit inside of DataRobot is currently in alpha. Check back soon for the opportunity to test out this functionality yourself.\n",
        "\n",
        "drum can run your training model to make sure it can produce a trained model artifact before adding the training model into DataRobot.\n",
        "\n",
        "Note: If you don't provide class label, DataRobot tries to autodetect the labels for you.\n",
        "\n",
        "You can also use drum on regression datasets, and soon you will also be able to provide row weights. Checkout the drum fit --help output for further details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LvOGsTdajy5",
        "outputId": "58e8437b-71d5-4410-8ab3-f1e5f4f9b5ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# install from pip\n",
        "%pip install sagemaker-scikit-learn-extension -q"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |██████▋                         | 10kB 22.7MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 20kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 30kB 3.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 40kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 2.3MB/s \n",
            "\u001b[?25h  Building wheel for sagemaker-scikit-learn-extension (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaGdEHjbajy8",
        "outputId": "7f84f804-1582-4364-c127-bbc4f9257bdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!drum fit --code-dir odsc-ml-drum/src/other_models/python3_sklearn_regression --target MEDV --input odsc-ml-drum/data/boston_housing.csv --output odsc-ml-drum/src/other_models/drum-fit-model --verbose"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Detected fit mode\n",
            "Detected /content/odsc-ml-drum/src/other_models/python3_sklearn_regression/custom.py .. trying to load hooks\n",
            "\u001b[32m \u001b[0m\n",
            "\u001b[32m \u001b[0m\n",
            "\u001b[32m============================================================\u001b[0m\n",
            "\u001b[32mComponent: python_fit\u001b[0m\n",
            "\u001b[32mLanguage:  Python\u001b[0m\n",
            "\u001b[32mOutput:\u001b[0m\n",
            "\u001b[32m------------------------------------------------------------\u001b[0m\n",
            "\u001b[32m------------------------------------------------------------\u001b[0m\n",
            "\u001b[32mRuntime:    0.1 sec\u001b[0m\n",
            "\u001b[32mNR outputs: 0\u001b[0m\n",
            "\u001b[32m============================================================\u001b[0m\n",
            "\u001b[32m \u001b[0m\n",
            "Maximum memory usage: 141MB\n",
            "Files were overwritten: {'/content/odsc-ml-drum/src/other_models/drum-fit-model/create_pipeline.py', '/content/odsc-ml-drum/src/other_models/drum-fit-model/custom.py', '/content/odsc-ml-drum/src/other_models/drum-fit-model/model-metadata.yaml', '/content/odsc-ml-drum/src/other_models/drum-fit-model/README.md'}\n",
            "Detected /content/odsc-ml-drum/src/other_models/drum-fit-model/custom.py .. trying to load hooks\n",
            "2020-11-03 18:46:27.371865: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "\u001b[32m \u001b[0m\n",
            "\u001b[32m \u001b[0m\n",
            "\u001b[32m============================================================\u001b[0m\n",
            "\u001b[32mComponent: generic_predictor\u001b[0m\n",
            "\u001b[32mLanguage:  Python\u001b[0m\n",
            "\u001b[32mOutput:\u001b[0m\n",
            "\u001b[32m------------------------------------------------------------\u001b[0m\n",
            "\u001b[32m------------------------------------------------------------\u001b[0m\n",
            "\u001b[32mRuntime:    0.0 sec\u001b[0m\n",
            "\u001b[32mNR outputs: 0\u001b[0m\n",
            "\u001b[32m============================================================\u001b[0m\n",
            "\u001b[32m \u001b[0m\n",
            "Success 🎉\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9MBcfLIajzA"
      },
      "source": [
        "## Perf-tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAli-2gdcCGH",
        "outputId": "6494da6c-ef03-43de-9899-a3fff27dcbe6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!drum perf-test --help"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: drum perf-test [-h] -cd CODE_DIR --input INPUT\n",
            "                      [--positive-class-label POSITIVE_CLASS_LABEL]\n",
            "                      [--negative-class-label NEGATIVE_CLASS_LABEL]\n",
            "                      [--class-labels CLASS_LABELS [CLASS_LABELS ...]]\n",
            "                      [--class-labels-file CLASS_LABELS_FILE]\n",
            "                      [--docker DOCKER] [--memory MEMORY] [-s SAMPLES]\n",
            "                      [-i ITERATIONS] [--timeout TIMEOUT] [--in-server]\n",
            "                      [--url URL] [--production] [--max-workers MAX_WORKERS]\n",
            "                      [--language {python,r,java}] [--show-stacktrace]\n",
            "                      [--target-type {binary,multiclass,regression,anomaly,unstructured}]\n",
            "                      [--query QUERY] [--content-type CONTENT_TYPE]\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  -cd CODE_DIR, --code-dir CODE_DIR\n",
            "                        Custom model code dir\n",
            "  --input INPUT         Path to an input dataset\n",
            "  --positive-class-label POSITIVE_CLASS_LABEL\n",
            "                        Positive class label for a binary classification case.\n",
            "  --negative-class-label NEGATIVE_CLASS_LABEL\n",
            "                        Negative class label for a binary classification case.\n",
            "  --class-labels CLASS_LABELS [CLASS_LABELS ...]\n",
            "                        The class labels for a multiclass classification case.\n",
            "                        Labels should be in the order as the predicted\n",
            "                        probabilities produced by the model.\n",
            "  --class-labels-file CLASS_LABELS_FILE\n",
            "                        A file containing newline separated class labels for a\n",
            "                        multiclass classification case. Labels should be in\n",
            "                        the order as the predicted probabilities produced by\n",
            "                        the model.\n",
            "  --docker DOCKER       Docker image to use to run drum in the perf-test mode,\n",
            "                        or a directory, containing a Dockerfile, which can be\n",
            "                        built into a docker image.\n",
            "  --memory MEMORY       Amount of memory to allow the docker container to\n",
            "                        consume. The value will be passed to the docker run\n",
            "                        command to both the --memory and --memory-swap\n",
            "                        parameters. b,k,m,g suffixes are supported\n",
            "  -s SAMPLES, --samples SAMPLES\n",
            "                        Number of samples\n",
            "  -i ITERATIONS, --iterations ITERATIONS\n",
            "                        Number of iterations\n",
            "  --timeout TIMEOUT     Test case timeout\n",
            "  --in-server           Show performance inside server\n",
            "  --url URL             Run performance against the given prediction server\n",
            "  --production          Run prediction server in production mode uwsgi + nginx\n",
            "  --max-workers MAX_WORKERS\n",
            "                        Max number of uwsgi workers in server production mode\n",
            "  --language {python,r,java}\n",
            "                        Language to use for the new model/env template to\n",
            "                        create\n",
            "  --show-stacktrace     Show stacktrace when error happens.\n",
            "  --target-type {binary,multiclass,regression,anomaly,unstructured}\n",
            "                        Target type\n",
            "  --query QUERY         Additional query params unstructured mode. (Simulates\n",
            "                        http request query params.)\n",
            "  --content-type CONTENT_TYPE\n",
            "                        Additional content type for unstructured mode.\n",
            "                        (Simulates http request Content-Type header, default:\n",
            "                        'text/plain; charset=utf8')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sx_CRwntajzB",
        "outputId": "48ec01ab-f8ad-401e-93b9-7cd73bf3a9fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!drum perf-test -cd odsc-ml-drum/src/other_models/drum-fit-model --input odsc-ml-drum/data/boston_housing_inference.csv --target-type regression --show-stacktrace"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preparing test data...\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/drum\", line 6, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/datarobot_drum/drum/main.py\", line 96, in main\n",
            "    CMRunner(runtime).run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/datarobot_drum/drum/drum.py\", line 290, in run\n",
            "    CMRunTests(self.options, self.run_mode).performance_test()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/datarobot_drum/drum/perf_testing.py\", line 306, in performance_test\n",
            "    self._server_process = subprocess.Popen(cmd_list, env=env_vars)\n",
            "  File \"/usr/lib/python3.6/subprocess.py\", line 729, in __init__\n",
            "    restore_signals, start_new_session)\n",
            "  File \"/usr/lib/python3.6/subprocess.py\", line 1295, in _execute_child\n",
            "    restore_signals, start_new_session, preexec_fn)\n",
            "TypeError: expected str, bytes or os.PathLike object, not NoneType\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwLCB4xbajzE"
      },
      "source": [
        "## Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "tPyIIy4TajzF",
        "outputId": "f4dc77d5-1c38-4a33-ccf5-d7b5783e8997",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!drum validation --code-dir odsc-ml-drum/src/other_models/drum-fit-model --input odsc-ml-drum/data/boston_housing.csv --target-type regression > drum_validation.log\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-03 18:49:00.535803: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/compose/_column_transformer.py:430: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
            "  FutureWarning)\n",
            "2020-11-03 18:49:04.652209: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/compose/_column_transformer.py:430: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
            "  FutureWarning)\n",
            "2020-11-03 18:49:08.711748: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/compose/_column_transformer.py:430: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
            "  FutureWarning)\n",
            "2020-11-03 18:49:12.725248: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/compose/_column_transformer.py:430: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
            "  FutureWarning)\n",
            "2020-11-03 18:49:16.994484: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/compose/_column_transformer.py:430: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
            "  FutureWarning)\n",
            "2020-11-03 18:49:21.566004: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/compose/_column_transformer.py:430: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
            "  FutureWarning)\n",
            "2020-11-03 18:49:25.623530: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/compose/_column_transformer.py:430: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
            "  FutureWarning)\n",
            "2020-11-03 18:49:29.651912: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/compose/_column_transformer.py:430: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
            "  FutureWarning)\n",
            "2020-11-03 18:49:33.653618: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/compose/_column_transformer.py:430: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
            "  FutureWarning)\n",
            "2020-11-03 18:49:37.674435: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/compose/_column_transformer.py:430: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
            "  FutureWarning)\n",
            "2020-11-03 18:49:41.741876: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/compose/_column_transformer.py:430: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
            "  FutureWarning)\n",
            "2020-11-03 18:49:45.786844: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/compose/_column_transformer.py:430: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
            "  FutureWarning)\n",
            "2020-11-03 18:49:49.820186: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/compose/_column_transformer.py:430: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
            "  FutureWarning)\n",
            "2020-11-03 18:49:53.835146: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/compose/_column_transformer.py:430: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
            "  FutureWarning)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-Zoc00-ajzH",
        "outputId": "d7a68738-2536-4355-abcb-3d52239e767c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!tail -20 drum_validation.log"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Predictions\n",
            "0      30.522568\n",
            "1      24.560272\n",
            "2      30.692869\n",
            "3      29.985301\n",
            "4      29.225193\n",
            "..           ...\n",
            "501    24.361584\n",
            "502    22.930635\n",
            "503    28.721774\n",
            "504    27.304425\n",
            "505    23.196687\n",
            "\n",
            "[506 rows x 1 columns]\n",
            "\n",
            "\n",
            "Validation checks results\n",
            "      Test case         Status\n",
            "==============================\n",
            "Null value imputation   PASSED\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPp4Fw4gajzK"
      },
      "source": [
        "## Score\n",
        "\n",
        "Score the data in batch model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeLQDoQsajzK",
        "outputId": "a05fad1d-45ca-410a-8dcf-86339845ad71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!drum score --code-dir odsc-ml-drum/src/other_models/drum-fit-model --input odsc-ml-drum/data/boston_housing_inference.csv --target-type regression --verbose\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Detected score mode\n",
            "Detected /content/odsc-ml-drum/src/other_models/drum-fit-model/custom.py .. trying to load hooks\n",
            "2020-11-03 18:50:32.593405: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "\u001b[32m \u001b[0m\n",
            "\u001b[32m \u001b[0m\n",
            "\u001b[32m============================================================\u001b[0m\n",
            "\u001b[32mComponent: generic_predictor\u001b[0m\n",
            "\u001b[32mLanguage:  Python\u001b[0m\n",
            "\u001b[32mOutput:\u001b[0m\n",
            "\u001b[32m------------------------------------------------------------\u001b[0m\n",
            "\u001b[32m------------------------------------------------------------\u001b[0m\n",
            "\u001b[32mRuntime:    0.0 sec\u001b[0m\n",
            "\u001b[32mNR outputs: 0\u001b[0m\n",
            "\u001b[32m============================================================\u001b[0m\n",
            "\u001b[32m \u001b[0m\n",
            "   Predictions\n",
            "0    30.522568\n",
            "1    24.560272\n",
            "2    30.692869\n",
            "3    29.985301\n",
            "4    29.225193\n",
            "5    26.322876\n",
            "6    22.370245\n",
            "7    18.959008\n",
            "8    10.061568\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4FECnaYajzN"
      },
      "source": [
        "## Server\n",
        "\n",
        "This will be covered in main notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JlMmBXrcmHr"
      },
      "source": [
        "import subprocess"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2pMKCIPajzN"
      },
      "source": [
        "inference_server = subprocess.Popen([\"drum\",  \"server\", \"--code-dir\", \"odsc-ml-drum/src/other_models/drum-fit-model\", \"--address\", \"localhost:1234\"]) "
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9WBSsfBc4E6"
      },
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from io import StringIO, BytesIO\n",
        "import os\n",
        "import time\n",
        "# -----------------------------------------------------------\n",
        "# Forms\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "## endpoint for model\n",
        "drum_url = \"http://localhost\"\n",
        "drum_port = \"1234\"\n",
        "def score(data, url = \"http://localhost\", port = \"1234\"):\n",
        "    b_buf = BytesIO()\n",
        "    b_buf.write(data.to_csv(index=False).encode(\"utf-8\"))\n",
        "    b_buf.seek(0) \n",
        "    url = \"{}:{}/predict/\".format(url, port)\n",
        "    files = [\n",
        "        ('X', b_buf)\n",
        "    ]\n",
        "    response = requests.request(\"POST\", url, files = files, timeout=None, verify=False)\n",
        "    return response"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-sbO0DsdZj5"
      },
      "source": [
        "df = pd.read_csv(\"odsc-ml-drum/data/boston_housing_inference.csv\")"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgMaGMPpdd9i",
        "outputId": "d3e55ae0-d983-4beb-bb6e-ac914ff0468e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "score(df,drum_url, drum_port).json()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'predictions': [30.5225680706,\n",
              "  24.5602720246,\n",
              "  30.6928692906,\n",
              "  29.9853006924,\n",
              "  29.2251933589,\n",
              "  26.3228764654,\n",
              "  22.3702449939,\n",
              "  18.9590083659,\n",
              "  10.0615675685]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjo46oCPajzQ",
        "outputId": "cefd96c9-3aaf-4dc2-cf8c-beb5c6c51cd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "requests.post(\"{}/shutdown/\".format(drum_url))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Response [200]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkakaEHedqxX"
      },
      "source": [
        "inference_server.terminate()\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAdDUlgtd4pw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}